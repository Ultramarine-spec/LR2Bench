# LR<sup>2</sup>Bench: Evaluating Long-chain Reflective Reasoning Capabilities of Large Language Models via Constraint Satisfaction Problems
<p align="center">
    ðŸ“– <a href="https://arxiv.org/abs/2502.17848" target="_blank">Paper</a> â€¢ ðŸ¤— <a href="https://huggingface.co/spaces/UltraRonin/LR2Bench" target="_blank">Leaderboard</a>
</p>


Currently, we only provide the data samples without corresponding golden answers. If you wish to test the model's performance or obtain more information, please contact us at our email address: [chenjianghao2022@ia.ac.cn](mailto:chenjianghao2022@ia.ac.cn). We will soon provide an automated evaluation system on our [leaderboard website](https://huggingface.co/spaces/UltraRonin/LR2Bench).


## ðŸ’¡ Generation
You can edit the tasks and models for generation in `launch.sh`.
```bash
bash launch.sh
```